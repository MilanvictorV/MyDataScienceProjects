{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c999aeec",
   "metadata": {},
   "source": [
    "### Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24450559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67981355",
   "metadata": {},
   "source": [
    "### Function to extract text contents from the given HTML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f398b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from HTML file\n",
    "def extract_text_from_html(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        table_data = []\n",
    "        for table in tables:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                cols = row.find_all(['td', 'th'])\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                table_data.append(cols)\n",
    "        flattened_list = [item for sublist in table_data for item in sublist]\n",
    "        return ' '.join(flattened_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5380f201",
   "metadata": {},
   "source": [
    "### Function to code the categories with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08c864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for coding the categories\n",
    "def category_coding(category):\n",
    "    return 0 if category == \"Balance Sheets\" else (1 if category == \"Cash Flow\" else (2 if category==\"Income Statement\" else(3 if category==\"Notes\" else 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9fac8",
   "metadata": {},
   "source": [
    "### Extracting the texts from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88c521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory path where all folders are located\n",
    "root_directory = '/Users/milan/Desktop/data'\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Iterate over each folder\n",
    "for folder_name in os.listdir(root_directory):\n",
    "    folder_path = os.path.join(root_directory, folder_name)\n",
    "    \n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over each HTML file in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith('.html'):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                # Extract text from HTML file\n",
    "                extracted_text = extract_text_from_html(file_path)\n",
    "                # Create a dataframe for the current HTML file\n",
    "                df = pd.DataFrame([[extracted_text, folder_name]], columns=[\"extracted_text\", \"category\"])\n",
    "                dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "final_df['category'] = final_df['category'].apply(category_coding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e228f",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19321732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(text):\n",
    "    # Defining the special characters to remove\n",
    "    special_chars = '!@#$%^&*()_+<>?/\\|.,:;\"{}[]`~'\n",
    "\n",
    "    # Removing punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + special_chars))\n",
    "\n",
    "    # Removing newline characters\n",
    "    text = text.replace('\\n', '')\n",
    "\n",
    "    return text\n",
    "final_df['extracted_text'] = final_df['extracted_text'].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef1e72",
   "metadata": {},
   "source": [
    "### Lowering all the letters in the extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbddc1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the wordtokenize instance to convert the sentence into tokens\n",
    "final_df['tokens'] = final_df['extracted_text'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2885f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the WordNetLemmatizer instance to convert all the tokens into it's original form\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#lemmatizing the tokens and joining the tokens into sentences\n",
    "final_df['lemmatized_text'] = final_df['tokens'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6a78980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>category</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash flows from financing activities    Decrea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Cash, flows, from, financing, activities, Dec...</td>\n",
       "      <td>Cash flow from financing activity Decrease Inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Year ended31st March 2018 Year ended31st Marc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Year, ended31st, March, 2018, Year, ended31st...</td>\n",
       "      <td>Year ended31st March 2018 Year ended31st March...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PARTICULARS As on 31032017 As on 31032016 Net ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[PARTICULARS, As, on, 31032017, As, on, 310320...</td>\n",
       "      <td>PARTICULARS As on 31032017 As on 31032016 Net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DESCRIPTION Year Ended March 31 2017 Year Ende...</td>\n",
       "      <td>1</td>\n",
       "      <td>[DESCRIPTION, Year, Ended, March, 31, 2017, Ye...</td>\n",
       "      <td>DESCRIPTION Year Ended March 31 2017 Year Ende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INR in Crores Particulars For the year ended ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[INR, in, Crores, Particulars, For, the, year,...</td>\n",
       "      <td>INR in Crores Particulars For the year ended F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Outstanding Balances    Million Name of the Re...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Outstanding, Balances, Million, Name, of, the...</td>\n",
       "      <td>Outstanding Balances Million Name of the Relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>Particulars December 31 2017 December 31 2016 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Particulars, December, 31, 2017, December, 31...</td>\n",
       "      <td>Particulars December 31 2017 December 31 2016 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>13  Cash and cash equivalents Rupees in Millio...</td>\n",
       "      <td>3</td>\n",
       "      <td>[13, Cash, and, cash, equivalents, Rupees, in,...</td>\n",
       "      <td>13 Cash and cash equivalent Rupees in Million ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>31 December 2017INR in Lacs 31 December 2016I...</td>\n",
       "      <td>3</td>\n",
       "      <td>[31, December, 2017INR, in, Lacs, 31, December...</td>\n",
       "      <td>31 December 2017INR in Lacs 31 December 2016IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>NOTE 8 OTHER FINANCIAL ASSETS LONG TERM NONCUR...</td>\n",
       "      <td>3</td>\n",
       "      <td>[NOTE, 8, OTHER, FINANCIAL, ASSETS, LONG, TERM...</td>\n",
       "      <td>NOTE 8 OTHER FINANCIAL ASSETS LONG TERM NONCUR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2525 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         extracted_text  category  \\\n",
       "0     Cash flows from financing activities    Decrea...         1   \n",
       "1      Year ended31st March 2018 Year ended31st Marc...         1   \n",
       "2     PARTICULARS As on 31032017 As on 31032016 Net ...         1   \n",
       "3     DESCRIPTION Year Ended March 31 2017 Year Ende...         1   \n",
       "4      INR in Crores Particulars For the year ended ...         1   \n",
       "...                                                 ...       ...   \n",
       "2520  Outstanding Balances    Million Name of the Re...         3   \n",
       "2521  Particulars December 31 2017 December 31 2016 ...         3   \n",
       "2522  13  Cash and cash equivalents Rupees in Millio...         3   \n",
       "2523   31 December 2017INR in Lacs 31 December 2016I...         3   \n",
       "2524  NOTE 8 OTHER FINANCIAL ASSETS LONG TERM NONCUR...         3   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [Cash, flows, from, financing, activities, Dec...   \n",
       "1     [Year, ended31st, March, 2018, Year, ended31st...   \n",
       "2     [PARTICULARS, As, on, 31032017, As, on, 310320...   \n",
       "3     [DESCRIPTION, Year, Ended, March, 31, 2017, Ye...   \n",
       "4     [INR, in, Crores, Particulars, For, the, year,...   \n",
       "...                                                 ...   \n",
       "2520  [Outstanding, Balances, Million, Name, of, the...   \n",
       "2521  [Particulars, December, 31, 2017, December, 31...   \n",
       "2522  [13, Cash, and, cash, equivalents, Rupees, in,...   \n",
       "2523  [31, December, 2017INR, in, Lacs, 31, December...   \n",
       "2524  [NOTE, 8, OTHER, FINANCIAL, ASSETS, LONG, TERM...   \n",
       "\n",
       "                                        lemmatized_text  \n",
       "0     Cash flow from financing activity Decrease Inc...  \n",
       "1     Year ended31st March 2018 Year ended31st March...  \n",
       "2     PARTICULARS As on 31032017 As on 31032016 Net ...  \n",
       "3     DESCRIPTION Year Ended March 31 2017 Year Ende...  \n",
       "4     INR in Crores Particulars For the year ended F...  \n",
       "...                                                 ...  \n",
       "2520  Outstanding Balances Million Name of the Relat...  \n",
       "2521  Particulars December 31 2017 December 31 2016 ...  \n",
       "2522  13 Cash and cash equivalent Rupees in Million ...  \n",
       "2523  31 December 2017INR in Lacs 31 December 2016IN...  \n",
       "2524  NOTE 8 OTHER FINANCIAL ASSETS LONG TERM NONCUR...  \n",
       "\n",
       "[2525 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final dataframe before splitting into training and testing data.\n",
    "# Here we are not lowering and removing the stopwords as TfidfVectorizer will handle all these things\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a2880",
   "metadata": {},
   "source": [
    "### Model is not balanced well and it's a text data so will do oversampling after making them vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e26ff79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the 70% data for training and 30% data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df['lemmatized_text'], final_df['category'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc67ac98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-validation accuracy: 0.9276\n",
      "Naive Bayes Cross-validation accuracy: 0.8172\n",
      "SVM Cross-validation accuracy: 0.9349\n",
      "Decision Tree Cross-validation accuracy: 0.8432\n",
      "Random Forest Cross-validation accuracy: 0.9236\n",
      "Gradient Boosting Cross-validation accuracy: 0.9134\n"
     ]
    }
   ],
   "source": [
    "# Initialising all the classification models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('SVM', SVC(probability=True)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "for model_name, model in models:\n",
    "    pipeline = make_pipeline(TfidfVectorizer(), model)\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "    print(f'{model_name} Cross-validation accuracy: {scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc419f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test accuracy: 0.9406\n"
     ]
    }
   ],
   "source": [
    "best_model_pipeline = make_pipeline(TfidfVectorizer(), SVC(probability=True))\n",
    "best_model_pipeline.fit(X_train, y_train)\n",
    "test_accuracy = best_model_pipeline.score(X_test, y_test)\n",
    "print(f'SVM Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a46e8a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross-validation AUROC score: 0.9932\n",
      "Naive Bayes Cross-validation AUROC score: 0.9450\n",
      "SVM Cross-validation AUROC score: 0.9944\n",
      "Decision Tree Cross-validation AUROC score: 0.8679\n",
      "Random Forest Cross-validation AUROC score: 0.9930\n",
      "Gradient Boosting Cross-validation AUROC score: 0.9904\n"
     ]
    }
   ],
   "source": [
    "# Defining a custom scorer for roc_auc_ovr\n",
    "scorer_roc_auc_ovr = make_scorer(roc_auc_score, needs_proba=True, multi_class='ovr')\n",
    "\n",
    "# Perform cross-validation with roc_auc_ovr scoring\n",
    "for model_name, model in models:\n",
    "    pipeline = make_pipeline(TfidfVectorizer(), model)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=scorer_roc_auc_ovr)\n",
    "    print(f'{model_name} Cross-validation AUROC score: {scores.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b7fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression\n",
      "Average Logistic Regression Accuracy Percentage: 93.0367 %\n",
      "Evaluating Naive Bayes\n",
      "Average Naive Bayes Accuracy Percentage: 82.1723 %\n",
      "Evaluating SVM\n",
      "Average SVM Accuracy Percentage: 94.1121 %\n",
      "Evaluating Decision Tree\n",
      "Average Decision Tree Accuracy Percentage: 85.6815 %\n",
      "Evaluating Random Forest\n",
      "Average Random Forest Accuracy Percentage: 93.1481 %\n",
      "Evaluating Gradient Boosting\n",
      "Average Gradient Boosting Accuracy Percentage: 92.0740 %\n"
     ]
    }
   ],
   "source": [
    "# Defining the number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initializing StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Defining the models\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('SVM', SVC(probability=True)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Initializing TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Looping through each model\n",
    "for model_name, model in models:\n",
    "    print(f'Evaluating {model_name}')\n",
    "    \n",
    "    # Initializing a list to store accuracy scores for each fold\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    # Looping through each fold\n",
    "    for fold, (train_index, test_index) in enumerate(k_fold.split(X_train, y_train)):\n",
    "        # Split the data into train and test sets\n",
    "        X_fold_train, X_fold_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_fold_train, y_fold_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        \n",
    "        # Create a pipeline with TF-IDF Vectorizer and the model\n",
    "        pipeline = make_pipeline(tfidf_vectorizer, model)\n",
    "        \n",
    "        # Fit the model on the training data\n",
    "        pipeline.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Predict on the test data\n",
    "        y_pred = pipeline.predict(X_fold_test)\n",
    "        \n",
    "        # Calculate accuracy for this fold and store it\n",
    "        accuracy = accuracy_score(y_fold_test, y_pred)\n",
    "        fold_accuracies.append(accuracy)\n",
    "    \n",
    "    # Calculating and printing the average accuracy across all folds\n",
    "    average_accuracy = sum(fold_accuracies) / n_splits * 100\n",
    "    print(f'Average {model_name} Accuracy Percentage: {average_accuracy:.4f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d3e419",
   "metadata": {},
   "source": [
    "## By conclusion, for our use cause SVM will be the best model to select, because it's giving the highest of accuracy compared to all other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290b910",
   "metadata": {},
   "source": [
    "### To test the model, please give the file path in the below given code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72aa99c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given document is classfied as: Others\n"
     ]
    }
   ],
   "source": [
    "test_file = '/Users/milan/Desktop/data/Others/18582961_8.html'\n",
    "test_extracted_from_file = extract_text_from_html(test_file)\n",
    "noise_removed_text = remove_noise(test_extracted_from_file)\n",
    "tokenised_text = word_tokenize(noise_removed_text)\n",
    "lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in tokenised_text])\n",
    "predicted_value = best_model_pipeline.predict([lemmatized_text])\n",
    "print(\"Given document is classfied as:\",\"Balance Sheets\" if predicted_value == 0 else (\"Cash Flow\" if predicted_value == 1 else (\"Income Statement\" if predicted_value == 2 else(\"Notes\" if predicted_value == 3 else \"Others\"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
